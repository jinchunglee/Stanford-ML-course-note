# 第三章：模型與框架

## 3.1 模型與框架的區別

### 模型的定義
- **模型（Model）** 是用來描述數據和目標之間規律的數學表達式或計算規則。
- 機器學習模型的核心目的是從數據中學習模式，並基於學到的規則對新數據進行預測。

#### **模型特性：**
1. **具體性**：模型是針對特定任務設計的，學習特定的數據規律。
2. **靜態性**：一旦模型訓練完成，其結構和參數基本固定，用於預測或應用。

### 框架的定義
- **框架（Framework）** 是一個更高層次的概念，通常是基於多個模型的組合來完成更複雜的任務，或者提供整體性解決方案。
- 框架通常規定了數據流轉、模型更新或集成的流程。

#### **框架特性：**
1. **通用性**：框架能處理不同類型的數據和任務。
2. **動態性**：框架能夠隨著數據更新，動態調整模型。

---

## 3.2 常見模型：線性回歸、決策樹、神經網絡

### 1. **線性回歸（Linear Regression）**
- **概念**：假設輸入特徵和輸出目標之間存在線性關係。
- **公式**：
  \[
  y = w_1x_1 + w_2x_2 + \dots + w_nx_n + b
  \]
  其中 \(w\) 為權重，\(b\) 為偏置。

#### **特點：**
1. 簡單易解釋。
2. 適用於輸入和輸出之間為線性關係的情況。

#### **例子：**
- 根據廣告費用（特徵），預測銷售額（目標）。

---

### 2. **決策樹（Decision Tree）**
- **概念**：一種基於分割規則的模型，通過「如果-那麼」的方式劃分數據。
- **結構**：由節點和分支構成，最終形成葉節點，代表最終的決策或預測值。

#### **特點：**
1. 不需要對數據進行過多的預處理。
2. 能處理非線性關係。

#### **例子：**
- 判斷一個顧客是否會購買產品，基於特徵（年齡、收入等）。

---

### 3. **神經網絡（Neural Networks）**
- **概念**：模仿生物神經網絡設計，通過多層結構學習數據中的非線性模式。
- **結構**：
  - **輸入層**：接收數據特徵。
  - **隱藏層**：通過激活函數學習模式。
  - **輸出層**：輸出預測結果。

#### **特點：**
1. 能處理高維數據和複雜關係。
2. 適用於圖像、語音等結構化或非結構化數據。

#### **例子：**
- 圖像識別（輸入像素矩陣，輸出對應的分類標籤）。

---

## 3.3 框架的作用：梯度提升、Stacking、深度學習框架

### **1. 梯度提升框架（Gradient Boosting Framework）**
- **概念**：基於弱學習器（如決策樹）的累加，通過學習前一個模型的殘差，不斷提升整體性能。
- **主要算法**：
  - GBDT（Gradient Boosting Decision Tree）
  - XGBoost
  - CatBoost
- **適用場景**：回歸與分類問題，尤其是在結構化數據中表現優異。

#### **例子：**
- 預測客戶是否會流失，基於歷史行為數據。

---

### **2. Stacking（堆疊學習框架）**
- **概念**：一種集成學習方法，通過多層模型組合提升性能。
- **結構**：
  - 第一層：多個基模型獨立訓練。
  - 第二層：元模型學習基模型的輸出結果。

#### **適用場景：**
- 當不同模型能捕捉不同特徵模式時。

#### **例子：**
- 第一層：線性回歸、決策樹。
- 第二層：用邏輯回歸作為元模型，整合結果。

---

### **3. 深度學習框架**
- **概念**：支持神經網絡的訓練和部署，常用於非結構化數據（如圖像、語音）。
- **主要框架**：
  - TensorFlow
  - PyTorch
- **特點**：自動支持梯度計算和多層結構設計。

#### **例子：**
- 圖片生成模型（GAN），從隨機噪聲生成清晰圖片。

---

## 總結
本章介紹了模型和框架的區別，並重點闡述了常見模型（如線性回歸、決策樹、神經網絡）的特點與應用。同時，簡述了三種主流框架（梯度提升、Stacking、深度學習框架）的運作原理和場景。後續章節將深入探討各框架的具體實現。

