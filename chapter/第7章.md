# 第七章：集成學習

## 7.1 集成學習的概念與類型

### 什麼是集成學習？
集成學習（Ensemble Learning）是一種通過結合多個基模型（Base Models）的預測結果來提升模型整體性能的技術。其核心思想是「集體智慧」：多個基模型的組合通常比單一模型表現更優秀。

### 為什麼需要集成學習？
1. **提升準確性**：集成模型通常能降低偏差（Bias）和方差（Variance）。
2. **穩定性強**：不同基模型的預測結果能互補，減少單一模型的錯誤。
3. **適用性廣**：能處理分類、回歸、多目標等多種任務。

---

### 集成學習的三種類型
1. **Bagging（Bootstrap Aggregating）**
   - 透過隨機抽樣生成多個訓練子集，每個子集訓練一個基模型，最終通過投票（分類）或平均（回歸）輸出結果。
   - 代表算法：隨機森林（Random Forest）。

2. **Boosting**
   - 基於弱模型的累加提升性能，每個新模型專注於修正前一個模型的錯誤。
   - 代表算法：梯度提升（Gradient Boosting）、XGBoost、CatBoost。

3. **Stacking**
   - 使用多個基模型的輸出作為次級模型（Meta-Model）的輸入，通過次級模型學習基模型的組合方式。
   - 代表算法：堆疊學習（Stacked Generalization）。

---

## 7.2 Bagging 方法

### 1. 核心思想
- 通過「隨機采樣 + 平行訓練」生成多個基模型，將每個模型的輸出進行組合。
- **目標**：降低模型的方差（Variance），提升穩定性。

### 2. 代表算法：隨機森林（Random Forest）
- 隨機森林是一種基於決策樹的 Bagging 方法，通過以下兩個隨機性來減少過擬合：
  1. **隨機選擇特徵**：每棵樹僅使用部分特徵進行分割。
  2. **隨機選擇樣本**：每棵樹從原始數據集中隨機采樣。

### 3. 優勢與局限
- **優勢**：
  1. 適用於高維數據。
  2. 抗噪能力強，對異常值不敏感。
- **局限**：
  1. 模型解釋性較弱。
  2. 訓練過程相對耗時。

---

## 7.3 Boosting 方法

### 1. 核心思想
- 逐步累加基模型，每個新模型專注於修正前一個模型的錯誤。
- **目標**：降低偏差（Bias），提升模型精度。

### 2. 代表算法
#### **2.1 梯度提升（Gradient Boosting）**
- 基於損失函數的梯度信息，每棵樹學習當前模型的殘差。
- 適用於分類與回歸問題。

#### **2.2 XGBoost**
- **特點**：
  1. 引入正則化項，防止過擬合。
  2. 支持並行運算，加速訓練。
- **應用場景**：結構化數據的分類或回歸。

#### **2.3 CatBoost**
- **特點**：
  1. 原生支持類別型特徵。
  2. 通過有序 Boosting 減少數據洩露問題。
- **應用場景**：處理含類別型特徵的數據（如用戶行為預測）。

---

### 3. 優勢與局限
- **優勢**：
  1. 適合非線性數據。
  2. 在少量數據上也能取得不錯的效果。
- **局限**：
  1. 訓練時間長，計算成本高。
  2. 對異常值敏感。

---

## 7.4 Stacking 方法

### 1. 核心思想
- 使用多個基模型進行初步預測，將基模型的輸出作為次級模型的輸入，最終由次級模型生成結果。
- **目標**：利用不同模型的優勢，提升整體性能。

### 2. 結構
1. **第一層**：多個基模型（如線性回歸、決策樹、神經網絡）進行獨立訓練。
2. **第二層**：次級模型（如邏輯回歸）學習基模型輸出的組合方式。

---

### 3. 優勢與局限
- **優勢**：
  1. 能同時利用不同類型模型的優勢。
  2. 表現通常比單一算法更好。
- **局限**：
  1. 訓練過程較為複雜。
  2. 次級模型可能會過擬合。

---

### 4. 值得舉例的場景
#### 堆疊學習示例
1. **問題**：預測用戶是否會購買某產品。
2. **解法**：
   - 第一層基模型：線性回歸、隨機森林、XGBoost。
   - 第二層次級模型：邏輯回歸，結合第一層的預測結果進行決策。

---

## 7.5 集成學習的應用場景

1. **分類任務**
   - 用戶行為預測：通過集成學習方法提高用戶購買行為的預測準確性。
   - 疾病診斷：將多種模型組合應用於病症的檢測與診斷。

2. **回歸任務**
   - 房價預測：通過隨機森林或梯度提升準確估算房價。
   - 能源需求預測：結合多種回歸模型提高預測的穩定性。

3. **多目標學習**
   - 預測多項財務指標，如收入、支出、毛利率。

---

## 總結
本章深入探討了集成學習的三大核心方法（Bagging、Boosting、Stacking），並詳細介紹了各自的特點、優勢與應用場景。集成學習作為機器學習的重要技術之一，在提升模型性能與穩定性方面發揮了巨大作用。接下來的章節將進一步研究模型性能的評估方法。
