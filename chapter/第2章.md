# 第二章：監督式學習

## 2.1 監督式學習的概念與應用

### 定義
監督式學習（Supervised Learning）是機器學習中最常用的一種方法，通過使用**帶有標籤的數據**訓練模型，讓模型學習輸入與輸出之間的對應關係，並對未標記的新數據進行預測。

### 應用場景
1. **回歸（Regression）**
   - 預測連續值的目標，如房價預測、溫度預測。
2. **分類（Classification）**
   - 將輸入數據分類為不同類別，如垃圾郵件分類、圖片中物體的識別。

---

## 2.2 回歸問題：目標與應用

### 回歸的概念
回歸是一種監督式學習任務，目的是學習輸入數據（特徵）與目標值（連續數字）之間的對應關係，從而對未來數據進行預測。

### 常見方法
1. **線性回歸（Linear Regression）**
   - 假設輸入特徵與輸出值之間存在線性關係。
2. **多項式回歸（Polynomial Regression）**
   - 使用多項式函數擬合輸入與輸出之間的非線性關係。
3. **決策樹回歸（Decision Tree Regression）**
   - 基於分割規則進行回歸預測。

### 值得舉例的場景
#### 房價預測（線性回歸）
1. **問題**：預測房屋的價格。
2. **數據**：
   - 特徵：房屋面積、臥室數量。
   - 標籤：房屋價格。
3. **模型**：訓練一個線性回歸模型，學習面積和臥室數與房價之間的關係。

---

## 2.3 分類問題：目標與應用

### 分類的概念
分類是一種監督式學習任務，目的是根據輸入數據的特徵，將其分配到預定義的類別中。目標值是**離散類別**（例如 "是" 或 "否"）。

### 常見方法
1. **邏輯回歸（Logistic Regression）**
   - 適合處理二分類問題。
2. **支持向量機（SVM）**
   - 使用超平面將不同類別分隔開。
3. **決策樹分類（Decision Tree Classification）**
   - 基於條件分割數據，生成分類規則。
4. **K-近鄰算法（K-Nearest Neighbors, KNN）**
   - 根據與樣本最近鄰的數據點來分類。

### 值得舉例的場景
#### 垃圾郵件分類（邏輯回歸）
1. **問題**：判斷一封郵件是否是垃圾郵件。
2. **數據**：
   - 特徵：郵件中的單詞頻率。
   - 標籤：垃圾郵件（1）或非垃圾郵件（0）。
3. **模型**：訓練一個邏輯回歸模型，學習特徵與類別之間的對應關係。

---

## 2.4 損失函數的基本概念與常見類型

### 定義
損失函數（Loss Function）是用來衡量模型預測值與真實值之間差異的指標，是模型訓練過程中需要最小化的目標。

### 常見損失函數
1. **均方誤差（MSE，Mean Squared Error）**  
   適用於回歸問題，計算預測值與真實值差距的平方平均值：
   \[
   \text{MSE} = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2
   \]
   - **應用**：房價預測。

2. **交叉熵損失（Cross-Entropy Loss）**  
   適用於分類問題，衡量預測概率分布與真實分布之間的差異：
   \[
   \text{Cross-Entropy} = -\frac{1}{n} \sum_{i=1}^n y_i \log(\hat{y}_i)
   \]
   - **應用**：垃圾郵件分類。

3. **Huber 損失（Huber Loss）**
   - 同時考慮均方誤差和絕對誤差的優點，對異常值更具有魯棒性。

### 值得舉例的場景
#### 房價預測中的 MSE
1. **情境**：某城市的房價預測模型，目標是最小化預測價格與真實價格的均方誤差。
2. **公式解釋**：模型輸出的房價預測值 \(\hat{y}_i\) 與真實值 \(y_i\) 之間的差異平方越小，損失越小。

---

## 總結
本章重點介紹了監督式學習的核心概念，包括回歸和分類問題的目標、常見方法與應用場景。此外，還概述了損失函數的基本概念與常見類型，這是後續模型訓練的重要基石。
